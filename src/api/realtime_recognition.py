# å®æ—¶äººè„¸è¯†åˆ«API
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from flask import Blueprint, request, jsonify, Response
import cv2
import numpy as np
import pickle
from datetime import datetime, timedelta
import base64
import time

from src.config import SIMILARITY_THRESHOLD, CAPTURE_DIR
from src.realtime_utils import draw_faces_with_names
from src.attendance import record_attendance
from insightface.app import FaceAnalysis
import os

realtime_recognition_bp = Blueprint('realtime_recognition', __name__, url_prefix='/api/realtime')

# å…¨å±€å˜é‡
face_app = None
known_names = []
known_feats = None
last_attendance = {}
camera_active = False
camera_instance = None

def initialize_face_app():
    """åˆå§‹åŒ–äººè„¸è¯†åˆ«æ¨¡å‹"""
    global face_app
    if face_app is None:
        face_app = FaceAnalysis(providers=['CPUExecutionProvider'])
        face_app.prepare(ctx_id=0, det_size=(320, 320))
    return face_app

def load_known_faces():
    """åŠ è½½å·²æ³¨å†Œçš„å­¦ç”Ÿç‰¹å¾"""
    global known_names, known_feats
    pkl_path = project_root / "data" / "students.pkl"
    if not pkl_path.exists():
        return False, "æœªæ‰¾åˆ° students.pklï¼Œè¯·å…ˆæ³¨å†Œå­¦ç”Ÿ"
    
    try:
        with open(pkl_path, 'rb') as f:
            data = pickle.load(f)
        known_names = list(data.keys())
        known_feats = np.array(list(data.values()))
        return True, f"æˆåŠŸåŠ è½½ {len(known_names)} åå­¦ç”Ÿ"
    except Exception as e:
        return False, f"åŠ è½½å¤±è´¥: {str(e)}"

@realtime_recognition_bp.route('/start-camera', methods=['POST'])
def start_camera():
    """å¯åŠ¨æ‘„åƒå¤´"""
    global camera_active, camera_instance
    
    try:
        print("ğŸ“· æ”¶åˆ°å¯åŠ¨æ‘„åƒå¤´è¯·æ±‚")
        
        if camera_active:
            print("âš ï¸ æ‘„åƒå¤´å·²åœ¨è¿è¡Œ")
            return jsonify({"success": False, "message": "æ‘„åƒå¤´å·²åœ¨è¿è¡Œ"}), 400
        
        # åŠ è½½äººè„¸æ•°æ®åº“
        print("ğŸ“š æ­£åœ¨åŠ è½½äººè„¸æ•°æ®åº“...")
        success, message = load_known_faces()
        print(f"ğŸ“š åŠ è½½ç»“æœ: {message}")
        if not success:
            return jsonify({"success": False, "message": message}), 400
        
        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–äººè„¸è¯†åˆ«æ¨¡å‹...")
        initialize_face_app()
        print("âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰“å¼€æ‘„åƒå¤´
        data = request.get_json() if request.is_json else {}
        camera_index = data.get('camera_index', 0) if data else 0
        print(f"ğŸ“¹ æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})...")
        camera_instance = cv2.VideoCapture(camera_index)
        
        if not camera_instance.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return jsonify({"success": False, "message": "æ— æ³•æ‰“å¼€æ‘„åƒå¤´"}), 500
        
        camera_active = True
        print(f"âœ“ æ‘„åƒå¤´å·²å¯åŠ¨ï¼Œå…±åŠ è½½ {len(known_names)} åå­¦ç”Ÿ")
        return jsonify({
            "success": True,
            "message": "æ‘„åƒå¤´å·²å¯åŠ¨",
            "students_count": len(known_names)
        })
    except Exception as e:
        import traceback
        print(f"âŒ å¯åŠ¨æ‘„åƒå¤´å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return jsonify({"success": False, "message": f"å¯åŠ¨å¤±è´¥: {str(e)}"}), 500

@realtime_recognition_bp.route('/stop-camera', methods=['POST'])
def stop_camera():
    """åœæ­¢æ‘„åƒå¤´"""
    global camera_active, camera_instance
    
    try:
        if camera_instance:
            camera_instance.release()
            camera_instance = None
        camera_active = False
        return jsonify({"success": True, "message": "æ‘„åƒå¤´å·²åœæ­¢"})
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500

@realtime_recognition_bp.route('/camera-status', methods=['GET'])
def camera_status():
    """è·å–æ‘„åƒå¤´çŠ¶æ€"""
    return jsonify({
        "success": True,
        "active": camera_active,
        "students_count": len(known_names)
    })

@realtime_recognition_bp.route('/process-frame', methods=['POST'])
def process_frame():
    """å¤„ç†å•å¸§å›¾åƒå¹¶è¿”å›è¯†åˆ«ç»“æœ"""
    global last_attendance
    
    try:
        # è·å–base64å›¾åƒ
        data = request.get_json()
        image_data = data.get('image')
        
        if not image_data:
            return jsonify({"success": False, "message": "ç¼ºå°‘å›¾åƒæ•°æ®"}), 400
        
        # è§£ç base64
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        img_bytes = base64.b64decode(image_data)
        nparr = np.frombuffer(img_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return jsonify({"success": False, "message": "æ— æ•ˆçš„å›¾åƒæ•°æ®"}), 400
        
        # ç¡®ä¿æ¨¡å‹å’Œæ•°æ®å·²åŠ è½½
        if face_app is None:
            initialize_face_app()
        
        if len(known_names) == 0:
            success, message = load_known_faces()
            if not success:
                return jsonify({"success": False, "message": message}), 400
        
        # æ£€æµ‹äººè„¸
        if face_app is None or known_feats is None or len(known_names) == 0:
            return jsonify({"success": False, "message": "äººè„¸è¯†åˆ«ç³»ç»Ÿæœªåˆå§‹åŒ–"}), 400
            
        faces = face_app.get(frame)
        current_time = datetime.now()
        
        results = []
        should_record = data.get('record', True)  # æ˜¯å¦è®°å½•è€ƒå‹¤
        
        for face in faces:
            feat = face.normed_embedding
            sims = np.dot(known_feats, feat)
            max_idx = np.argmax(sims)
            max_sim = float(sims[max_idx])
            name = known_names[max_idx]
            
            recognized = max_sim >= SIMILARITY_THRESHOLD
            recorded = False
            
            if recognized and should_record:
                # æ£€æŸ¥å†·å´æœŸï¼ˆ5åˆ†é’Ÿï¼‰
                can_record = True
                if name in last_attendance:
                    if current_time - last_attendance[name] < timedelta(minutes=5):
                        can_record = False
                
                if can_record:
                    last_attendance[name] = current_time
                    
                    # ä¿å­˜æˆªå›¾
                    os.makedirs(CAPTURE_DIR, exist_ok=True)
                    timestamp = current_time.strftime("%Y%m%d_%H%M%S")
                    filename = f"{name}_{timestamp}.jpg"
                    capture_path = os.path.join(CAPTURE_DIR, filename)
                    
                    bbox = face.bbox.astype(int)
                    x1, y1, x2, y2 = bbox
                    face_img = frame[y1:y2, x1:x2]
                    if face_img.size > 0:
                        cv2.imwrite(capture_path, face_img)
                    
                    # è®°å½•è€ƒå‹¤
                    record_attendance(
                        name=name,
                        course_date=current_time.date(),
                        image_path=capture_path,
                        confidence=max_sim,
                        status="present",
                        remark="å®æ—¶æ‘„åƒå¤´ç­¾åˆ°"
                    )
                    recorded = True
                    
                    # å¹¿æ’­WebSocketäº‹ä»¶ï¼ˆåœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­ï¼‰
                    try:
                        from src.api.app import socketio
                        socketio.emit('new_signin', {
                            'student_name': name,
                            'confidence': round(max_sim, 4),
                            'status': 'present',
                            'timestamp': current_time.isoformat(),
                            'message': f'{name} ç­¾åˆ°æˆåŠŸ'
                        })
                        print(f"ğŸ“¢ å¹¿æ’­ç­¾åˆ°äº‹ä»¶: {name} (ç½®ä¿¡åº¦: {max_sim:.4f})")
                    except Exception as e:
                        print(f"âš ï¸ WebSocketå¹¿æ’­å¤±è´¥: {e}")
            
            # æ„å»ºäººè„¸æ¡†ä¿¡æ¯
            bbox = face.bbox.astype(int).tolist()
            results.append({
                "name": name if recognized else "Unknown",
                "confidence": max_sim,
                "recognized": recognized,
                "recorded": recorded,
                "bbox": bbox
            })
        
        # ç»˜åˆ¶æ ‡æ³¨
        annotated_frame = frame.copy()
        for idx, face in enumerate(faces):
            result = results[idx]
            bbox = result['bbox']
            x1, y1, x2, y2 = bbox
            
            color = (0, 255, 0) if result['recognized'] else (0, 0, 255)
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            
            label = f"{result['name']} ({result['confidence']:.2f})"
            cv2.putText(annotated_frame, label, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # ç¼–ç è¿”å›
        _, buffer = cv2.imencode('.jpg', annotated_frame)
        annotated_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
        
        return jsonify({
            "success": True,
            "faces": results,
            "annotated_image": f"data:image/jpeg;base64,{annotated_base64}"
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500

@realtime_recognition_bp.route('/reload-database', methods=['POST'])
def reload_database():
    """é‡æ–°åŠ è½½äººè„¸æ•°æ®åº“"""
    try:
        success, message = load_known_faces()
        return jsonify({
            "success": success,
            "message": message,
            "students_count": len(known_names) if success else 0
        })
    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500
