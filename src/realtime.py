# å®æ—¶ç­¾åˆ°
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.pathï¼ˆå…¼å®¹ç›´æ¥è¿è¡Œï¼‰
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

import cv2
import numpy as np
import pickle
from datetime import datetime, timedelta
import os
import argparse

from src.config import (
    MODEL_NAME,
    SIMILARITY_THRESHOLD,
    CAPTURE_DIR,
    OUTPUTS_DIR
)
from src.realtime_utils import draw_faces_with_names
from src.attendance import record_attendance
from src.databaseBuild.db import DB_PATH
import insightface
from insightface.app import FaceAnalysis


def load_known_faces():
    """åŠ è½½å·²æ³¨å†Œçš„å­¦ç”Ÿç‰¹å¾"""
    pkl_path = project_root / "data" / "students.pkl"
    if not pkl_path.exists():
        print("âŒ æœªæ‰¾åˆ° students.pklï¼Œè¯·å…ˆè¿è¡Œ register.py")
        return [], []
    with open(pkl_path, 'rb') as f:
        data = pickle.load(f)
    names = list(data.keys())
    feats = list(data.values())
    return names, feats


def realtime_attendance(camera_index=0, save_captures=True):
    # åˆå§‹åŒ–æ¨¡å‹
    app = FaceAssistant(model_name=MODEL_NAME)
    
    # åŠ è½½å·²çŸ¥äººè„¸
    known_names, known_feats = load_known_faces()
    if not known_names:
        return

    # è½¬ä¸º NumPy æ•°ç»„ä¾¿äºè®¡ç®—
    known_feats = np.array(known_feats)

    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})")
        return

    # è®°å½•æœ€è¿‘ç­¾åˆ°æ—¶é—´ï¼š{name: last_time}
    last_attendance = {}

    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_captures:
        os.makedirs(CAPTURE_DIR, exist_ok=True)

    print("ğŸ¥ å®æ—¶ç­¾åˆ°å·²å¯åŠ¨ï¼æŒ‰ 'q' é€€å‡ºã€‚")
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
            break

        # æ£€æµ‹å¹¶è¯†åˆ«äººè„¸
        faces = app.get(frame)
        current_time = datetime.now()

        results = []
        for face in faces:
            feat = face.normed_embedding
            sims = np.dot(known_feats, feat)
            max_idx = np.argmax(sims)
            max_sim = sims[max_idx]
            name = known_names[max_idx]

            if max_sim >= SIMILARITY_THRESHOLD:
                # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…(é»˜è®¤1.5å°æ—¶)
                can_record = True
                if name in last_attendance:
                    if current_time - last_attendance[name] < timedelta(seconds=5400):
                        can_record = False

                if can_record:
                    last_attendance[name] = current_time

                    # ä¿å­˜æˆªå›¾ï¼ˆå¯é€‰ï¼‰
                    image_path = ""
                    if save_captures:
                        timestamp = current_time.strftime("%Y%m%d_%H%M%S")
                        filename = f"{name}_{timestamp}.jpg"
                        capture_path = os.path.join(CAPTURE_DIR, filename)
                        # è£å‰ªäººè„¸åŒºåŸŸ
                        bbox = face.bbox.astype(int)
                        x1, y1, x2, y2 = bbox
                        face_img = frame[y1:y2, x1:x2]
                        if face_img.size > 0:
                            cv2.imwrite(capture_path, face_img)
                            image_path = capture_path

                    # è®°å½•è€ƒå‹¤
                    record_attendance(
                        name=name,
                        course_date=current_time.date(),
                        image_path=image_path,
                        confidence=float(max_sim),
                        status="present",
                        remark="å®æ—¶ç­¾åˆ°"
                    )

                results.append((name, max_sim, can_record))
            else:
                results.append(("Unknown", max_sim, False))

        # ç»˜åˆ¶ç»“æœ
        display_frame = draw_faces_with_names(frame.copy(), faces, results)

        # æ˜¾ç¤ºç”»é¢
        cv2.imshow("Real-time Attendance (Press 'q' to quit)", display_frame)

        # æŒ‰ q é€€å‡º
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("ğŸ‘‹ å®æ—¶ç­¾åˆ°å·²å…³é—­ã€‚")


class FaceAssistant:
    def __init__(self, model_name='buffalo_l'):
        self.app = FaceAnalysis(name=model_name, providers=['CPUExecutionProvider'])
        self.app.prepare(ctx_id=0, det_size=(640, 640))

    def get(self, img):
        return self.app.get(img)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å®æ—¶äººè„¸ç­¾åˆ°ç³»ç»Ÿ")
    parser.add_argument("--camera", type=int, default=0, help="æ‘„åƒå¤´ç´¢å¼•ï¼Œé»˜è®¤ 0")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜ç­¾åˆ°æˆªå›¾")
    args = parser.parse_args()

    realtime_attendance(
        camera_index=args.camera,
        save_captures=not args.no_save
    )